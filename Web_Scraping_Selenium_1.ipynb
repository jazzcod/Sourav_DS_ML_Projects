{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst || SQL,Python, R || Bangalore</td>\n",
       "      <td>Binary Semantics Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst PowerBI Bangalore</td>\n",
       "      <td>Talent Corner HR Services Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bion</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - I</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Perficient India Private Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Chennai, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bengaluru(2nd Phase JP Nagar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looking For Rockstar Data Analyst @ Freshtohom...</td>\n",
       "      <td>Freshtohome Foods Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SAP Data Analyst</td>\n",
       "      <td>JOHN CRANE SEALING SYSTEMS INDIA PVT. LTD.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         Data Analyst || SQL,Python, R || Bangalore   \n",
       "1                     Data Analyst PowerBI Bangalore   \n",
       "2                                       Data Analyst   \n",
       "3                                   Data Analyst - I   \n",
       "4                                       Data Analyst   \n",
       "5                   Hiring Data Analysts on Contract   \n",
       "6                   Hiring Data Analysts on Contract   \n",
       "7                                       Data Analyst   \n",
       "8  Looking For Rockstar Data Analyst @ Freshtohom...   \n",
       "9                                   SAP Data Analyst   \n",
       "\n",
       "                                      company experience_required  \\\n",
       "0                    Binary Semantics Limited             3-7 Yrs   \n",
       "1           Talent Corner HR Services Pvt Ltd             1-3 Yrs   \n",
       "2                                        Bion             2-4 Yrs   \n",
       "3                                Novel Office             0-3 Yrs   \n",
       "4            Perficient India Private Limited             3-8 Yrs   \n",
       "5           Flipkart Internet Private Limited             2-5 Yrs   \n",
       "6           Flipkart Internet Private Limited             2-5 Yrs   \n",
       "7                              Liventus, Inc.             3-6 Yrs   \n",
       "8           Freshtohome Foods Private Limited             2-5 Yrs   \n",
       "9  JOHN CRANE SEALING SYSTEMS INDIA PVT. LTD.             3-7 Yrs   \n",
       "\n",
       "                        location  \n",
       "0                      Bengaluru  \n",
       "1          Bengaluru / Bangalore  \n",
       "2                      Bengaluru  \n",
       "3                      Bengaluru  \n",
       "4             Chennai, Bengaluru  \n",
       "5                      Bengaluru  \n",
       "6                      Bengaluru  \n",
       "7  Bengaluru(2nd Phase JP Nagar)  \n",
       "8                      Bengaluru  \n",
       "9                      Bengaluru  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url=(\"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url)\n",
    "\n",
    "#creating empty list\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "location_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "    \n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_list.append(location_name)\n",
    "\n",
    "#finding tags of the experience names\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "#finding text element in experience tags\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "\n",
    "#creating a dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs[\"title\"]=job_titles[:10]\n",
    "jobs[\"company\"]=company_names[:10]\n",
    "jobs[\"experience_required\"]=experience_list[:10]\n",
    "jobs[\"location\"]=location_list[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/sql</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\n\\nSkill: SQL, Python, Busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Data Scientist - Data Mining/ Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist - Machine/Deep Learni...</td>\n",
       "      <td>Fidius advisory</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description :\\n- We are looking for a rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atos Syntel Private Limited</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Working experience in Artificial Intelligence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Chennai, Pune, Bengaluru</td>\n",
       "      <td>Key Responsibilities\\nBe responsible for scali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>Roles and Responsibilities\\nSkill : NLP,Semant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMust have strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are hiring Data Scientist and Senior Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Analyst-Data Scientist</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Role Description:\\nA Sr. Data Scientist who le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                        Data Scientist - Python/sql   \n",
       "1  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3  Principal Data Scientist - Machine/Deep Learni...   \n",
       "4                                     Data Scientist   \n",
       "5                       Senior / Lead Data Scientist   \n",
       "6             Senior Data Scientist - NLP/ Python/ R   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8  Data Scientist and Senior Data Scientist Acade...   \n",
       "9                         Sr. Analyst-Data Scientist   \n",
       "\n",
       "                        company  \\\n",
       "0                      Catalyst   \n",
       "1  Wrackle Technologies Pvt Ltd   \n",
       "2  Wrackle Technologies Pvt Ltd   \n",
       "3               Fidius advisory   \n",
       "4   Atos Syntel Private Limited   \n",
       "5   TVS CREDIT SERVICES LIMITED   \n",
       "6            AVI Consulting LLP   \n",
       "7                      CES Ltd.   \n",
       "8        RANDSTAD INDIA PVT LTD   \n",
       "9              Mindtree Limited   \n",
       "\n",
       "                                            location  \\\n",
       "0                                          Bengaluru   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "5                           Chennai, Pune, Bengaluru   \n",
       "6                               Bengaluru, Hyderabad   \n",
       "7  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "8                                          Bengaluru   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job description\\n\\nSkill: SQL, Python, Busines...  \n",
       "1  Data Scientist - Data Mining/ Machine Learning...  \n",
       "2  Roles and Responsibilities\\nRequirements :\\n\\n...  \n",
       "3  Job Description :\\n- We are looking for a rese...  \n",
       "4  Working experience in Artificial Intelligence,...  \n",
       "5  Key Responsibilities\\nBe responsible for scali...  \n",
       "6  Roles and Responsibilities\\nSkill : NLP,Semant...  \n",
       "7  Roles and Responsibilities\\n\\nMust have strong...  \n",
       "8  We are hiring Data Scientist and Senior Data S...  \n",
       "9  Role Description:\\nA Sr. Data Scientist who le...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url1=(\"https://www.naukri.com/job-listings-data-scientist-python-sql-catalyst-bengaluru-bangalore-2-to-7-years-081119903383?src=jobsearchDesk&sid=16131618602304001&xp=1&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url1)\n",
    "\n",
    "#creating empty list\n",
    "job_name_1=[]\n",
    "company_name_1=[]\n",
    "location_name_1=[]\n",
    "job_description_1=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_1.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_1.append(company_name)\n",
    "company_name_1=company_name_1[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_1.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_1.append(job_description)\n",
    "job_description_1=job_description_1[:1]\n",
    "\n",
    "jobs_1=pd.DataFrame({})\n",
    "jobs_1[\"title\"]=job_name_1\n",
    "jobs_1[\"company\"]=company_name_1\n",
    "jobs_1[\"location\"]=location_name_1\n",
    "jobs_1[\"job_description\"]=job_description_1\n",
    "\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url2=(\"https://www.naukri.com/job-listings-data-scientist-python-matlab-machine-learning-algorithms-wrackle-technologies-pvt-ltd-bengaluru-bangalore-3-to-8-years-080221905947?src=jobsearchDesk&sid=16131666921196657&xp=1&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url2)\n",
    "\n",
    "#creating empty list\n",
    "job_name_2=[]\n",
    "company_name_2=[]\n",
    "location_name_2=[]\n",
    "job_description_2=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_2.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_2.append(company_name)\n",
    "company_name_2=company_name_2[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_2.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "job_description_tags\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_2.append(job_description)\n",
    "job_description_2=job_description_2[:1]\n",
    "\n",
    "jobs_2=pd.DataFrame({})\n",
    "jobs_2[\"title\"]=job_name_2\n",
    "jobs_2[\"company\"]=company_name_2\n",
    "jobs_2[\"location\"]=location_name_2\n",
    "jobs_2[\"job_description\"]=job_description_2\n",
    "\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url3=(\"https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bengaluru-bangalore-6-to-11-years-080221900886?src=jobsearchDesk&sid=16131672806199684&xp=2&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url3)\n",
    "\n",
    "#creating empty list\n",
    "job_name_3=[]\n",
    "company_name_3=[]\n",
    "location_name_3=[]\n",
    "job_description_3=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_3.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_3.append(company_name)\n",
    "company_name_3=company_name_3[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_3.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_3.append(job_description)\n",
    "job_description_3=job_description_3[:1]\n",
    "\n",
    "jobs_3=pd.DataFrame({})\n",
    "jobs_3[\"title\"]=job_name_3\n",
    "jobs_3[\"company\"]=company_name_3\n",
    "jobs_3[\"location\"]=location_name_3\n",
    "jobs_3[\"job_description\"]=job_description_3\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url4=(\"https://www.naukri.com/job-listings-principal-data-scientist-machine-deep-learning-nlp-tensorflow-fidius-advisory-bengaluru-bangalore-8-to-13-years-070720900498?src=jobsearchDesk&sid=16131682972292745&xp=4&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url4)\n",
    "\n",
    "#creating empty list\n",
    "job_name_4=[]\n",
    "company_name_4=[]\n",
    "location_name_4=[]\n",
    "job_description_4=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_4.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_4.append(company_name)\n",
    "company_name_4=company_name_4[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_4.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_4.append(job_description)\n",
    "job_description_4=job_description_4[:1]\n",
    "\n",
    "jobs_4=pd.DataFrame({})\n",
    "jobs_4[\"title\"]=job_name_4\n",
    "jobs_4[\"company\"]=company_name_4\n",
    "jobs_4[\"location\"]=location_name_4\n",
    "jobs_4[\"job_description\"]=job_description_4\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url5=(\"https://www.naukri.com/job-listings-data-scientist-atos-syntel-private-limited-chennai-pune-mumbai-bengaluru-bangalore-12-to-18-years-220719001543?src=jobsearchDesk&sid=16131686888815822&xp=5&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url5)\n",
    "\n",
    "#creating empty list\n",
    "job_name_5=[]\n",
    "company_name_5=[]\n",
    "location_name_5=[]\n",
    "job_description_5=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_5.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_5.append(company_name)\n",
    "company_name_5=company_name_5[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_5.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_5.append(job_description)\n",
    "job_description_5=job_description_5[:1]\n",
    "\n",
    "jobs_5=pd.DataFrame({})\n",
    "jobs_5[\"title\"]=job_name_5\n",
    "jobs_5[\"company\"]=company_name_5\n",
    "jobs_5[\"location\"]=location_name_5\n",
    "jobs_5[\"job_description\"]=job_description_5\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url6=(\"https://www.naukri.com/job-listings-senior-lead-data-scientist-tvs-credit-services-limited-chennai-pune-bengaluru-bangalore-3-to-8-years-261220002239?src=jobsearchDesk&sid=16131699479845590&xp=8&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url6)\n",
    "\n",
    "#creating empty list\n",
    "job_name_6=[]\n",
    "company_name_6=[]\n",
    "location_name_6=[]\n",
    "job_description_6=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_6.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_6.append(company_name)\n",
    "company_name_6=company_name_6[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_6.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_6.append(job_description)\n",
    "job_description_6=job_description_6[:1]\n",
    "\n",
    "jobs_6=pd.DataFrame({})\n",
    "jobs_6[\"title\"]=job_name_6\n",
    "jobs_6[\"company\"]=company_name_6\n",
    "jobs_6[\"location\"]=location_name_6\n",
    "jobs_6[\"job_description\"]=job_description_6\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url7=(\"https://www.naukri.com/job-listings-senior-data-scientist-nlp-python-r-avi-consulting-llp-bengaluru-bangalore-hyderabad-secunderabad-4-to-9-years-081220907155?src=jobsearchDesk&sid=16131702209617368&xp=9&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url7)\n",
    "\n",
    "#creating empty list\n",
    "job_name_7=[]\n",
    "company_name_7=[]\n",
    "location_name_7=[]\n",
    "job_description_7=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_7.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_7.append(company_name)\n",
    "company_name_7=company_name_7[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_7.append(location_name)\n",
    "    \n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_7.append(job_description)\n",
    "job_description_7=job_description_7[:1]\n",
    "\n",
    "jobs_7=pd.DataFrame({})\n",
    "jobs_7[\"title\"]=job_name_7\n",
    "jobs_7[\"company\"]=company_name_7\n",
    "jobs_7[\"location\"]=location_name_7\n",
    "jobs_7[\"job_description\"]=job_description_7\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url8=(\"https://www.naukri.com/job-listings-senior-data-scientist-ces-it-ltd-cmmi-level-5-ces-ltd-chennai-pune-delhi-ncr-mumbai-bengaluru-bangalore-hyderabad-secunderabad-kolkata-2-to-7-years-151220006902?src=jobsearchDesk&sid=16131705275458060&xp=10&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url8)\n",
    "\n",
    "#creating empty list\n",
    "job_name_8=[]\n",
    "company_name_8=[]\n",
    "location_name_8=[]\n",
    "job_description_8=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_8.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_8.append(company_name)\n",
    "company_name_8=company_name_8[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_8.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_8.append(job_description)\n",
    "job_description_8=job_description_8[:1]\n",
    "\n",
    "jobs_8=pd.DataFrame({})\n",
    "jobs_8[\"title\"]=job_name_8\n",
    "jobs_8[\"company\"]=company_name_8\n",
    "jobs_8[\"location\"]=location_name_8\n",
    "jobs_8[\"job_description\"]=job_description_8\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url9=(\"https://www.naukri.com/job-listings-data-scientist-and-senior-data-scientist-academic-operations-randstad-india-pvt-ltd-bengaluru-bangalore-2-to-5-years-080221007079?src=jobsearchDesk&sid=16131711302642736&xp=11&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url9)\n",
    "\n",
    "#creating empty list\n",
    "job_name_9=[]\n",
    "company_name_9=[]\n",
    "location_name_9=[]\n",
    "job_description_9=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_9.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_9.append(company_name)\n",
    "company_name_9=company_name_9[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_9.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_9.append(job_description)\n",
    "job_description_9=job_description_9[:1]\n",
    "\n",
    "jobs_9=pd.DataFrame({})\n",
    "jobs_9[\"title\"]=job_name_9\n",
    "jobs_9[\"company\"]=company_name_9\n",
    "jobs_9[\"location\"]=location_name_9\n",
    "jobs_9[\"job_description\"]=job_description_9\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url10=(\"https://www.naukri.com/job-listings-sr-analyst-data-scientist-mindtree-limited-bengaluru-bangalore-10-to-15-years-040221502130?src=jobsearchDesk&sid=16131713670108924&xp=12&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url10)\n",
    "\n",
    "#creating empty list\n",
    "job_name_10=[]\n",
    "company_name_10=[]\n",
    "location_name_10=[]\n",
    "job_description_10=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_10.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_10.append(company_name)\n",
    "company_name_10=company_name_10[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_10.append(location_name)\n",
    "    \n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_10.append(job_description)\n",
    "job_description_10=job_description_10[:1]\n",
    "\n",
    "jobs_10=pd.DataFrame({})\n",
    "jobs_10[\"title\"]=job_name_10\n",
    "jobs_10[\"company\"]=company_name_10\n",
    "jobs_10[\"location\"]=location_name_10\n",
    "jobs_10[\"job_description\"]=job_description_10\n",
    "\n",
    "#combining two data frames\n",
    "frames=[jobs_1,jobs_2,jobs_3,jobs_4,jobs_5,jobs_6,jobs_7,jobs_8,jobs_9,jobs_10]\n",
    "result=pd.concat(frames,ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ciena</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst - Data Scientist</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>iNICU</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                    Data Scientist Machine Learning   \n",
       "5                  Business Analyst - Data Scientist   \n",
       "6                           Analyst - Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                       company experience_required  \\\n",
       "0       IBM India Pvt. Limited             4-8 Yrs   \n",
       "1    GABA Consultancy services             0-0 Yrs   \n",
       "2                        Ciena             5-6 Yrs   \n",
       "3               Country Veggie             1-3 Yrs   \n",
       "4                    Delhivery             1-3 Yrs   \n",
       "5  HyreFox Consultants Pvt Ltd             3-5 Yrs   \n",
       "6  HyreFox Consultants Pvt Ltd             1-3 Yrs   \n",
       "7             Amity University             6-8 Yrs   \n",
       "8                    BlackBuck             3-7 Yrs   \n",
       "9                        iNICU             1-5 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0                                   Gurgaon Gurugram  \n",
       "1                          Delhi NCR, Noida, Gurgaon  \n",
       "2                                   Gurgaon Gurugram  \n",
       "3  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...  \n",
       "4                                            Gurgaon  \n",
       "5                                            Gurgaon  \n",
       "6                                            Gurgaon  \n",
       "7                    Faridabad, Delhi NCR, Ghaziabad  \n",
       "8                                 Bengaluru, Gurgaon  \n",
       "9                                              Delhi  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url=(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&ctcFilter=3to6&cityType=25.9.31\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url)\n",
    "\n",
    "#creating empty list\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "location_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    \n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "    \n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_list.append(location_name)\n",
    "    \n",
    "#finding tags of the experience names\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "#finding text element in experience tags\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "\n",
    "#creating a dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs[\"title\"]=job_titles[:10]\n",
    "jobs[\"company\"]=company_names[:10]\n",
    "jobs[\"experience_required\"]=experience_list[:10]\n",
    "jobs[\"location\"]=location_list[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*\\nDoesn't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Awesome Phone. Slightly high price but worth. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      review_summary  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5  Highly recommended   \n",
       "3       5    Perfect product!   \n",
       "4       5           Brilliant   \n",
       "..    ...                 ...   \n",
       "95      5    Perfect product!   \n",
       "96      5   Worth every penny   \n",
       "97      5   Worth every penny   \n",
       "98      5           Wonderful   \n",
       "99      4        Nice product   \n",
       "\n",
       "                                          full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "..                                                ...  \n",
       "95  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "96  Best budget Iphone till date ❤️ go for it guys...  \n",
       "97  It’s been almost a month since I have been usi...  \n",
       "98  *Review after 10 months of usage*\\nDoesn't see...  \n",
       "99  Awesome Phone. Slightly high price but worth. ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "#getting the webdriver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the page url\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART\")\n",
    "\n",
    "for page in range(0,11):\n",
    "    \n",
    "    #getting tags for the ratings\n",
    "    rating_tags=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    \n",
    "    #geting tags for the reviews\n",
    "    review_tags=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    \n",
    "    #getting tags for the full reviews\n",
    "    full_review_tags=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    \n",
    "    #getting text element from the rating tags\n",
    "    for i in rating_tags:\n",
    "        ratings=i.text\n",
    "        rating.append(ratings)\n",
    "    \n",
    "    #getting text element from the review tags\n",
    "    for i in review_tags:\n",
    "        reviews=i.text\n",
    "        review_summary.append(reviews)\n",
    "    \n",
    "    #getting text element from the full review tags\n",
    "    for i in full_review_tags:\n",
    "        full=i.text\n",
    "        full_review.append(full)\n",
    "    \n",
    "Iphone=pd.DataFrame({})\n",
    "Iphone[\"rating\"]=rating[:100]\n",
    "Iphone[\"review_summary\"]=review_summary[:100]\n",
    "Iphone[\"full_review\"]=full_review[:100]\n",
    "Iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise  6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_job.send_keys(\"Sunglasses\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_class_name(\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Aviator Sunglasses (88)</td>\n",
       "      <td>₹255</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹398</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer, Aviator Sunglasses (88)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>Night Vision, Polarized, UV Protection, Riding...</td>\n",
       "      <td>₹314</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand                                product_description price  \\\n",
       "0       Silver Kartz              UV Protection Aviator Sunglasses (88)  ₹255   \n",
       "1       Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)  ₹246   \n",
       "2     ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹499   \n",
       "3           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "4           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "..               ...                                                ...   ...   \n",
       "95          Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹599   \n",
       "96          Fastrack  Gradient, Mirrored, UV Protection Round, Round...  ₹404   \n",
       "97  shah collections              UV Protection Aviator Sunglasses (58)  ₹398   \n",
       "98          Fastrack    UV Protection Wayfarer, Aviator Sunglasses (88)  ₹399   \n",
       "99      Silver Kartz  Night Vision, Polarized, UV Protection, Riding...  ₹314   \n",
       "\n",
       "   discount  \n",
       "0   78% off  \n",
       "1   83% off  \n",
       "2   77% off  \n",
       "3   37% off  \n",
       "4   37% off  \n",
       "..      ...  \n",
       "95  33% off  \n",
       "96  79% off  \n",
       "97  73% off  \n",
       "98  80% off  \n",
       "99  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#creating a loop for the page numbers\n",
    "for page in range(0,4):\n",
    "    \n",
    "    #finding tags for brand names\n",
    "    brand_name_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    \n",
    "    #finding tags for product description\n",
    "    product_description_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    #finding tags for price\n",
    "    price_tags=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    \n",
    "    #finding tags for discount\n",
    "    discount_tags=driver.find_elements_by_class_name(\"_3Ay6Sb\")\n",
    "    \n",
    "    #finding text element in brand tags \n",
    "    for i in brand_name_tags:\n",
    "        brand_name=i.text\n",
    "        brand.append(brand_name)\n",
    "        \n",
    "    #finding text element in description tags   \n",
    "    for i in product_description_tags:\n",
    "        product=i.text\n",
    "        product_description.append(product)\n",
    "        \n",
    "    #finding text element in price tags     \n",
    "    for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)\n",
    "    \n",
    "     #finding text element in discount tags \n",
    "    for i in discount_tags:\n",
    "        dis=i.text\n",
    "        discount.append(dis)\n",
    "        \n",
    "#creating a dataframe\n",
    "Sunglass=pd.DataFrame({})\n",
    "Sunglass[\"brand\"]=brand[:100]\n",
    "Sunglass[\"product_description\"]=product_description[:100]\n",
    "Sunglass[\"price\"]=price[:100]\n",
    "Sunglass[\"discount\"]=discount[:100]\n",
    "Sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_job.send_keys(\"sneakers\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_class_name(\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wildcraft</td>\n",
       "      <td>Nova Sneakers For Men</td>\n",
       "      <td>₹1,677</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMROX</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LeatherKraft</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Restinfoot</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Axter</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹242</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  brand                                product_description  \\\n",
       "0             Wildcraft                              Nova Sneakers For Men   \n",
       "1                 AMROX  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "2                Chevit  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "3          Robbie jones  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "4   World Wear Footwear     White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95         LeatherKraft  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "96           Restinfoot  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "97                Axter     White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "98               BRUTON  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "99             Red Tape                                   Sneakers For Men   \n",
       "\n",
       "     price discount  \n",
       "0   ₹1,677  52% off  \n",
       "1     ₹399  73% off  \n",
       "2     ₹474  76% off  \n",
       "3     ₹399  60% off  \n",
       "4     ₹474  76% off  \n",
       "..     ...      ...  \n",
       "95    ₹398  60% off  \n",
       "96    ₹349  65% off  \n",
       "97    ₹236  52% off  \n",
       "98    ₹242  65% off  \n",
       "99    ₹379  62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#creating a loop for the page numbers\n",
    "for page in range(0,4):\n",
    "    \n",
    "    #finding tags for brand names\n",
    "    brand_name_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    \n",
    "    #finding tags for product description\n",
    "    product_description_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    #finding tags for price\n",
    "    price_tags=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    \n",
    "    #finding tags for discount\n",
    "    discount_tags=driver.find_elements_by_class_name(\"_3Ay6Sb\")\n",
    "    \n",
    "    #finding text element in brand tags \n",
    "    for i in brand_name_tags:\n",
    "        brand_name=i.text\n",
    "        brand.append(brand_name)\n",
    "        \n",
    "    #finding text element in description tags   \n",
    "    for i in product_description_tags:\n",
    "        product=i.text\n",
    "        product_description.append(product)\n",
    "        \n",
    "    #finding text element in price tags     \n",
    "    for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)\n",
    "    \n",
    "     #finding text element in discount tags \n",
    "    for i in discount_tags:\n",
    "        dis=i.text\n",
    "        discount.append(dis)\n",
    "        \n",
    "#creating a dataframe\n",
    "Sneakers=pd.DataFrame({})\n",
    "Sneakers[\"brand\"]=brand[:100]\n",
    "Sneakers[\"product_description\"]=product_description[:100]\n",
    "Sneakers[\"price\"]=price[:100]\n",
    "Sneakers[\"discount\"]=discount[:100]\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\" https://www.myntra.com/shoes\")\n",
    "\n",
    "#clicking the price filter\n",
    "price_btn=driver.find_element_by_class_name(\"price-num\")\n",
    "driver.execute_script(\"arguments[0].click();\", price_btn)\n",
    "\n",
    "#clicking the colour filter\n",
    "colour_btn=driver.find_element_by_class_name(\"colour-num\")\n",
    "driver.execute_script(\"arguments[0].click();\", colour_btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN ZOOM '92 Shoes</td>\n",
       "      <td>Rs. 10796Rs. 13495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JOYRIDE Running Shoes</td>\n",
       "      <td>Rs. 11996Rs. 14995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM VOMERO Running</td>\n",
       "      <td>Rs. 10796Rs. 13495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men SOLAR DRIVE 19 M Running</td>\n",
       "      <td>Rs. 8399Rs. 11999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Women Flexagon Training Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Textured Derbys</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand                    description  \\\n",
       "0                   Nike      Men JORDAN ZOOM '92 Shoes   \n",
       "1                   Nike    Men JORDAN DELTA Basketball   \n",
       "2                   Nike      Men JOYRIDE Running Shoes   \n",
       "3                   Nike    Men AIR ZOOM VOMERO Running   \n",
       "4                 ADIDAS   Men SOLAR DRIVE 19 M Running   \n",
       "..                   ...                            ...   \n",
       "95  Heel & Buckle London            Women Leather Pumps   \n",
       "96          Hush Puppies            Men Leather Loafers   \n",
       "97             Cole Haan    Men Wingtip Oxford Sneakers   \n",
       "98                Reebok  Women Flexagon Training Shoes   \n",
       "99                 Ruosh            Men Textured Derbys   \n",
       "\n",
       "                          price  \n",
       "0   Rs. 10796Rs. 13495(20% OFF)  \n",
       "1                     Rs. 12495  \n",
       "2   Rs. 11996Rs. 14995(20% OFF)  \n",
       "3   Rs. 10796Rs. 13495(20% OFF)  \n",
       "4    Rs. 8399Rs. 11999(30% OFF)  \n",
       "..                          ...  \n",
       "95    Rs. 7192Rs. 8990(20% OFF)  \n",
       "96                     Rs. 6999  \n",
       "97                    Rs. 12999  \n",
       "98                     Rs. 7999  \n",
       "99                     Rs. 8990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "#creating a for loop for the pages\n",
    "for page in range(0,4):\n",
    "    \n",
    "    #getting tags for the brand\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    \n",
    "    #getting tags for the description\n",
    "    description_tags=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    \n",
    "    #getting tags for he prices\n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    \n",
    "    #getting text element in the brand tags\n",
    "    for i in brand_tags:\n",
    "        brand_name=i.text\n",
    "        brand.append(brand_name)\n",
    "    \n",
    "    #getting text element in the description tags\n",
    "    for i in description_tags:\n",
    "        des=i.text\n",
    "        description.append(des)\n",
    "    \n",
    "    #getting text element in the price tags\n",
    "    for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)\n",
    "\n",
    "#creating dataframe        \n",
    "Shoes=pd.DataFrame({})\n",
    "Shoes[\"brand\"]=brand[:100]\n",
    "Shoes[\"description\"]=description[:100]\n",
    "Shoes[\"price\"]=price[:100]\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading drivers\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting url\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "#assigning delay\n",
    "time.sleep(5)\n",
    "\n",
    "#getting tags for search bar\n",
    "try:\n",
    "    search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    search_bar.send_keys(\"Laptop\")\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised: \",e)\n",
    "    search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    search_bar.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting clikable tags\n",
    "try:\n",
    "    search_click=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "    search_click.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised: \",e)\n",
    "    search_click=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "    search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locating the core i9 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting tags for the titles\n",
    "title_tags=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "\n",
    "#getting tags for the ratings\n",
    "rating_tags=driver.find_elements_by_xpath(\"//span[@class='aa-size-medium a-color-base a-text-beside-button a-text-bold']\")\n",
    "\n",
    "#getting tags for the prices\n",
    "price_tags=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting text element in title tags\n",
    "for i in title_tags:\n",
    "        titles=i.text\n",
    "        title.append(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting text element in rating tags\n",
    "for i in rating_tags:\n",
    "        ratings=i.text\n",
    "        rating.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getitng text element in price tags\n",
    "for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Yoga S940 Intel Core i7 10th Gen 14\" UH...</td>\n",
       "      <td>1,19,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>50,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 5i 10th Gen Intel Core i7 15.6 i...</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>75,482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>1,97,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>2,68,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>96,133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch 120hz FHD Display...</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     price\n",
       "0  Lenovo Yoga S940 Intel Core i7 10th Gen 14\" UH...  1,19,990\n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i5-1...    50,999\n",
       "2  Lenovo Legion 5i 10th Gen Intel Core i7 15.6 i...    89,990\n",
       "3  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...    74,990\n",
       "4  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...    75,482\n",
       "5  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  1,97,200\n",
       "6  Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...    77,990\n",
       "7  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  2,68,325\n",
       "8  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...    96,133\n",
       "9  Dell G3 3500 Gaming 15.6inch 120hz FHD Display...    77,990"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in rating_tag:\n",
    "    if i.text is None :\n",
    "        ratings.append(\"--\") \n",
    "    else:\n",
    "        ratings.append(i.text)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.glassdoor.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting tags for the search bar\n",
    "search_bar_designation=driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "\n",
    "#sending keys to the search bar\n",
    "search_bar_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "#getting tags for the location bar\n",
    "search_bar_location=driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "\n",
    "#sending keys for the location bar\n",
    "search_bar_location.send_keys(\"Noida\")\n",
    "\n",
    "#clickng the search bar\n",
    "search_bar_click=driver.find_element_by_xpath(\"//button[@data-test='search-bar-submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an ampty list\n",
    "rating=[]\n",
    "companies=[]\n",
    "days_posted=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the companies tags\n",
    "company_tag=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']/span\")\n",
    "\n",
    "#getting the rating tags\n",
    "rating_tag=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "\n",
    "#getting the days posted tags\n",
    "days_tag=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding text element in the company tag\n",
    "for i in company_tag:\n",
    "    if i.text is None :\n",
    "        companies.append(\"--\") \n",
    "    else:\n",
    "        companies.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding text element in the daus posted tag\n",
    "for i in days_tag:\n",
    "    if i.text is None :\n",
    "        days_posted.append(\"--\") \n",
    "    else:\n",
    "        days_posted.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding text element in the ratong tags\n",
    "for i in rating_tag:\n",
    "    if i.text is None :\n",
    "        rating.append(\"--\") \n",
    "    else:\n",
    "        rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>company</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bloom AI</td>\n",
       "      <td>2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.7</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.7</td>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Emerging India Group</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>WishFin</td>\n",
       "      <td>19d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.4</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.7</td>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.4</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.7</td>\n",
       "      <td>Dürr AG</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ratings                       company  days\n",
       "0     5.0                      Bloom AI    2d\n",
       "1     3.7                         Adobe   10d\n",
       "2     3.7                Biz2Credit Inc  30d+\n",
       "3     4.0          Emerging India Group  30d+\n",
       "4     5.0                       WishFin   19d\n",
       "5     4.4  Salasar New Age Technologies  30d+\n",
       "6     3.7                      Techlive  30d+\n",
       "7     3.4                     Microsoft  30d+\n",
       "8     3.0  Salasar New Age Technologies  30d+\n",
       "9     3.7                       Dürr AG  30d+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "Glassdoor=pd.DataFrame({})\n",
    "Glassdoor[\"ratings\"]=rating[:10]\n",
    "Glassdoor[\"company\"]=companies[:10]\n",
    "Glassdoor[\"days\"]=days_posted[:10]\n",
    "Glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting tags for the search bar\n",
    "search_bar_designation=driver.find_element_by_xpath(\"//input[@id='KeywordSearch']\")\n",
    "\n",
    "#sending keys to the search bar\n",
    "search_bar_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "#getting tags for the location bar\n",
    "search_bar_location=driver.find_element_by_xpath(\"//input[@id='LocationSearch']\")\n",
    "\n",
    "#sending keys for the location bar\n",
    "search_bar_location.send_keys(\"Noida\")\n",
    "\n",
    "#clickng the search bar\n",
    "search_bar_click=driver.find_element_by_xpath(\"//button[@data-test='search-bar-submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an ampty list\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "company_name=[]\n",
    "avg_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the minimum salary tags\n",
    "min_tag=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span\")\n",
    "\n",
    "#getting the maximum salary tags\n",
    "max_tag=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span\")\n",
    "\n",
    "#getting the company name tags\n",
    "company_tag=driver.find_elements_by_xpath(\"//p[@class='m-0 ']\")\n",
    "\n",
    "#getting the average salary tags\n",
    "avg_tag=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding text element in the company tag\n",
    "for i in min_tag:\n",
    "    if i.text is None :\n",
    "        min_salary.append(\"--\") \n",
    "    else:\n",
    "        min_salary.append(i.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding text element in the company tag\n",
    "for i in company_tag:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding text element in the company tag\n",
    "for i in avg_tag:\n",
    "    if i.text is None :\n",
    "        avg_salary.append(\"--\") \n",
    "    else:\n",
    "        avg_salary.append(i.text)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_max_salary</th>\n",
       "      <th>company_name</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹450K</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,64,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₹11,630K</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,30,968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>₹350K</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>₹1,614K</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 9,94,055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>₹336K</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,39,040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹1,010K</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,37,114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>₹577K</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,80,374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>₹2,215K</td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹ 11,98,792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>₹587K</td>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹ 10,08,143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>₹2,732K</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,34,989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  min_max_salary                    company_name   avg_salary\n",
       "0          ₹450K                       Delhivery  ₹ 12,64,182\n",
       "1       ₹11,630K              Ericsson-Worldwide   ₹ 7,30,968\n",
       "2          ₹350K       Tata Consultancy Services   ₹ 6,00,000\n",
       "3        ₹1,614K                       Accenture   ₹ 9,94,055\n",
       "4          ₹336K                             IBM   ₹ 7,39,040\n",
       "5        ₹1,010K              UnitedHealth Group  ₹ 13,37,114\n",
       "6          ₹577K              Valiance Solutions   ₹ 7,80,374\n",
       "7        ₹2,215K                      Innovaccer  ₹ 11,98,792\n",
       "8          ₹587K  Cognizant Technology Solutions  ₹ 10,08,143\n",
       "9        ₹2,732K                     EXL Service  ₹ 11,34,989"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "Glassdoor=pd.DataFrame({})\n",
    "Glassdoor[\"min_max_salary\"]=min_salary[:10]\n",
    "Glassdoor[\"company_name\"]=company_name[:10]\n",
    "Glassdoor[\"avg_salary\"]=avg_salary[:10]\n",
    "Glassdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
